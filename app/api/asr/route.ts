import { NextRequest, NextResponse } from 'next/server';

const DASHSCOPE_API_KEY = process.env.DASHSCOPE_API_KEY;

export async function POST(request: NextRequest) {
  try {
    console.log('ğŸ¤ ===== ASRè¯­éŸ³è¯†åˆ«API =====');
    
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      return NextResponse.json({ 
        error: 'æœªæä¾›éŸ³é¢‘æ–‡ä»¶',
        success: false 
      }, { status: 400 });
    }

    console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯:', {
      name: audioFile.name,
      size: audioFile.size,
      type: audioFile.type
    });

    console.log('ğŸš€ å‘é€ASRè¯·æ±‚...');

    // å°†éŸ³é¢‘è½¬æ¢ä¸ºBase64
    const arrayBuffer = await audioFile.arrayBuffer();
    const base64Audio = Buffer.from(arrayBuffer).toString('base64');
    
    console.log('ğŸ“Š éŸ³é¢‘æ•°æ®å¤§å°:', base64Audio.length);

    // ä½¿ç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«API
    const response = await fetch('https://dashscope.aliyuncs.com/api/v1/services/aigc/asr/transcription', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${DASHSCOPE_API_KEY}`,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      },
      body: JSON.stringify({
        model: 'paraformer-realtime-v2',
        input: {
          audio: `data:audio/webm;base64,${base64Audio}`
        },
        parameters: {
          format: 'webm',
          sample_rate: 16000,
          language_hints: ['zh', 'en']
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('ğŸ’¥ ASRè¯·æ±‚å¤±è´¥:', response.status, errorText);
      return NextResponse.json({ 
        error: `ASRè¯·æ±‚å¤±è´¥: ${response.status}`,
        details: errorText,
        success: false 
      }, { status: 500 });
    }

    const result = await response.json();
    console.log('ğŸ“¥ ASRå“åº”:', JSON.stringify(result, null, 2));

    // è§£æå“åº”
    let recognizedText = '';
    
    if (result.output && result.output.text) {
      recognizedText = result.output.text;
    } else if (result.output && result.output.transcription) {
      recognizedText = result.output.transcription;
    } else if (result.text) {
      recognizedText = result.text;
    }

    if (!recognizedText || recognizedText.trim().length === 0) {
      console.log('âš ï¸ æœªè¯†åˆ«å‡ºæœ‰æ•ˆæ–‡æœ¬');
      return NextResponse.json({ 
        success: false, 
        text: '', 
        message: 'æœªè¯†åˆ«å‡ºæœ‰æ•ˆæ–‡æœ¬',
        debug: result
      });
    }

    console.log('âœ… ASRè¯†åˆ«å®Œæˆ:', `"${recognizedText}"`);

    // ğŸš€ è‡ªåŠ¨è°ƒç”¨LLMè¿›è¡Œå¯¹è¯
    console.log('ğŸ¤– å¼€å§‹è°ƒç”¨LLMå¯¹è¯...');
    try {
      const chatResponse = await fetch(`${request.nextUrl.origin}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message: recognizedText
        })
      });

      if (chatResponse.ok) {
        const chatResult = await chatResponse.json();
        console.log('ğŸ¤– LLMå›ç­”:', chatResult.response);
        
        return NextResponse.json({
          success: true,
          text: recognizedText,
          llmResponse: chatResult.response
        });
      } else {
        console.log('âš ï¸ LLMè°ƒç”¨å¤±è´¥ï¼Œä»…è¿”å›è¯†åˆ«æ–‡æœ¬');
        return NextResponse.json({
          success: true,
          text: recognizedText
        });
      }
    } catch (chatError) {
      console.error('ğŸ¤– LLMè°ƒç”¨å‡ºé”™:', chatError);
      return NextResponse.json({
        success: true,
        text: recognizedText
      });
    }

  } catch (error) {
    console.error('ğŸ’¥ ASRå¤„ç†å‡ºé”™:', error);
    return NextResponse.json({ 
      error: 'ASRå¤„ç†å¤±è´¥',
      details: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
      success: false 
    }, { status: 500 });
  }
} 