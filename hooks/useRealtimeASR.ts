import { useState, useRef, useCallback } from 'react';

interface UseRealtimeASROptions {
  onPartialResult?: (text: string) => void;
  onFinalResult?: (text: string) => void;
  onError?: (error: string) => void;
}

interface UseRealtimeASRReturn {
  isListening: boolean;
  status: 'idle' | 'starting' | 'listening' | 'stopping' | 'error';
  partialText: string;
  finalText: string;
  audioLevel: number;
  error: string | null;
  startListening: () => Promise<void>;
  stopListening: () => Promise<void>;
}

// è·å–æ”¯æŒçš„éŸ³é¢‘MIMEç±»å‹
function getSupportedMimeType(): string {
  // ä¼˜å…ˆä½¿ç”¨WAVæ ¼å¼ï¼Œé¿å…WebMè§£ç é—®é¢˜
  const types = [
    'audio/wav',
    'audio/mp4',
    'audio/ogg;codecs=opus',
    'audio/webm',
    'audio/webm;codecs=opus'
  ];
  
  for (const type of types) {
    if (MediaRecorder.isTypeSupported(type)) {
      console.log('âœ… ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', type);
      return type;
    }
  }
  
  console.warn('âš ï¸ ä½¿ç”¨é»˜è®¤éŸ³é¢‘æ ¼å¼');
  return 'audio/wav'; // é»˜è®¤æ ¼å¼æ”¹ä¸ºWAVï¼Œå…¼å®¹æ€§æ›´å¥½
}

// éŸ³é¢‘æ ¼å¼è½¬æ¢å‡½æ•°ï¼šæ”¯æŒå¤šç§æ ¼å¼è½¬PCM
async function convertToPCM(audioBlob: Blob): Promise<ArrayBuffer> {
  // æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
  if (audioBlob.size === 0) {
    throw new Error('éŸ³é¢‘æ•°æ®ä¸ºç©º');
  }

  if (audioBlob.size < 1024) { // æé«˜åˆ°1KB
    throw new Error('éŸ³é¢‘æ•°æ®å¤ªå°ï¼Œå¯èƒ½æ— æ•ˆ');
  }

  // æ£€æŸ¥MIMEç±»å‹æ˜¯å¦æœ‰æ•ˆ
  if (!audioBlob.type || audioBlob.type === '') {
    console.warn('âš ï¸ éŸ³é¢‘MIMEç±»å‹ç¼ºå¤±');
  }

  console.log('ğŸ”§ å¼€å§‹éŸ³é¢‘è½¬æ¢ï¼Œè¾“å…¥å¤§å°:', audioBlob.size, 'bytes, ç±»å‹:', audioBlob.type);
  
  let audioContext: AudioContext | null = null;
  
  try {
    audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    
    const arrayBuffer = await audioBlob.arrayBuffer();
    console.log('ğŸ“Š è¯»å–éŸ³é¢‘æ•°æ®ï¼Œå¤§å°:', arrayBuffer.byteLength, 'bytes');
    
    // æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®
    if (arrayBuffer.byteLength === 0) {
      throw new Error('éŸ³é¢‘ç¼“å†²åŒºä¸ºç©º');
    }

    // è§£ç éŸ³é¢‘æ•°æ®ï¼Œå¢åŠ æ›´å¥½çš„é”™è¯¯å¤„ç†
    let audioBuffer: AudioBuffer;
    try {
      audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
      console.log('âœ… éŸ³é¢‘è§£ç æˆåŠŸï¼Œé‡‡æ ·ç‡:', audioBuffer.sampleRate, 'å£°é“æ•°:', audioBuffer.numberOfChannels, 'æ—¶é•¿:', audioBuffer.duration.toFixed(3), 's');
    } catch (decodeError: any) {
      console.error('âŒ éŸ³é¢‘è§£ç å¤±è´¥:', decodeError.message);
      
      // å°è¯•å¤‡ç”¨è§£ç æ–¹æ³•
      try {
        console.log('ğŸ”„ å°è¯•å¤‡ç”¨è§£ç æ–¹æ³•...');
        const audioBuffer2 = await new Promise<AudioBuffer>((resolve, reject) => {
          audioContext!.decodeAudioData(
            arrayBuffer.slice(0), 
            resolve, 
            reject
          );
        });
        audioBuffer = audioBuffer2;
        console.log('âœ… å¤‡ç”¨è§£ç æˆåŠŸ');
      } catch (fallbackError: any) {
        throw new Error(`éŸ³é¢‘è§£ç å¤±è´¥: ${decodeError.message} (å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: ${fallbackError.message})`);
      }
    }
    
    // æ£€æŸ¥éŸ³é¢‘ç¼“å†²åŒºæ˜¯å¦æœ‰æ•ˆ
    if (!audioBuffer || audioBuffer.length === 0) {
      throw new Error('è§£ç åçš„éŸ³é¢‘ç¼“å†²åŒºæ— æ•ˆ');
    }

    // é‡é‡‡æ ·åˆ°16000Hzå•å£°é“
    const targetSampleRate = 16000;
    const length = Math.floor(audioBuffer.length * targetSampleRate / audioBuffer.sampleRate);
    
    if (length <= 0) {
      throw new Error('é‡é‡‡æ ·åé•¿åº¦æ— æ•ˆ');
    }

    const offlineContext = new OfflineAudioContext(1, length, targetSampleRate);
    
    const source = offlineContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(offlineContext.destination);
    source.start();
    
    const resampledBuffer = await offlineContext.startRendering();
    console.log('ğŸ”„ é‡é‡‡æ ·å®Œæˆï¼Œæ–°é•¿åº¦:', resampledBuffer.length, 'ç›®æ ‡é‡‡æ ·ç‡:', targetSampleRate);
    
    // è½¬æ¢ä¸º16ä½PCM
    const samples = resampledBuffer.getChannelData(0);
    const int16Array = new Int16Array(samples.length);
    
    for (let i = 0; i < samples.length; i++) {
      const s = Math.max(-1, Math.min(1, samples[i]));
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    
    console.log('âœ… PCMè½¬æ¢å®Œæˆï¼Œè¾“å‡ºå¤§å°:', int16Array.buffer.byteLength, 'bytes');
    return int16Array.buffer;
    
  } catch (error: any) {
    console.error('âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥:', error.message);
    throw new Error(`éŸ³é¢‘è½¬æ¢å¤±è´¥: ${error.message}`);
  } finally {
    if (audioContext && audioContext.state !== 'closed') {
      try {
        await audioContext.close();
      } catch (e) {
        console.warn('âš ï¸ éŸ³é¢‘ä¸Šä¸‹æ–‡å…³é—­å¤±è´¥:', e);
      }
    }
  }
}

export const useRealtimeASR = (options: UseRealtimeASROptions = {}): UseRealtimeASRReturn => {
  const [isListening, setIsListening] = useState(false);
  const [status, setStatus] = useState<'idle' | 'starting' | 'listening' | 'stopping' | 'error'>('idle');
  const [partialText, setPartialText] = useState('');
  const [finalText, setFinalText] = useState('');
  const [audioLevel, setAudioLevel] = useState(0);
  const [error, setError] = useState<string | null>(null);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const sessionIdRef = useRef<string | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  // æ›´æ–°éŸ³é¢‘ç”µå¹³
  const updateAudioLevel = useCallback(() => {
    if (analyserRef.current) {
      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
      analyserRef.current.getByteFrequencyData(dataArray);
      
      // è®¡ç®—å¹³å‡éŸ³é‡
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
      const level = Math.min(average / 128, 1); // å½’ä¸€åŒ–åˆ°0-1
      
      setAudioLevel(level);
      
      // ç»§ç»­åŠ¨ç”»å¾ªç¯
      if (isListening) {
        animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
      }
    }
  }, [isListening]);

  // å¼€å§‹å½•éŸ³
  const startListening = useCallback(async () => {
    try {
      setStatus('starting');
      setError(null);
      setPartialText('');
      setFinalText('');
      
      console.log('ğŸ¤ å¼€å§‹å¯åŠ¨è¯­éŸ³è¯†åˆ«...');

      // 1. å¯åŠ¨è¯†åˆ«ä¼šè¯
      const startResponse = await fetch('/api/realtime-asr', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ action: 'start' })
      });

      const startResult = await startResponse.json();
      if (!startResult.success) {
        throw new Error(startResult.error || 'å¯åŠ¨ä¼šè¯å¤±è´¥');
      }

      sessionIdRef.current = startResult.session_id;
      console.log('âœ… è¯­éŸ³è¯†åˆ«ä¼šè¯å·²å¯åŠ¨ï¼ŒID:', sessionIdRef.current);

      // 2. è·å–éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 48000, // ä½¿ç”¨æ›´é«˜çš„é‡‡æ ·ç‡ï¼Œç„¶åè½¬æ¢
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      streamRef.current = stream;

      // 3. è®¾ç½®éŸ³é¢‘åˆ†æå™¨ï¼ˆç”¨äºæ˜¾ç¤ºéŸ³é¢‘ç”µå¹³ï¼‰
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 256;
      source.connect(analyserRef.current);

      // 4. è·å–æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
      const mimeType = getSupportedMimeType();
      
      // 5. è®¾ç½®å½•éŸ³å™¨
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType
      });
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      // 6. å¤„ç†å½•éŸ³æ•°æ®
      mediaRecorder.ondataavailable = async (event) => {
        if (event.data.size > 0) {
          console.log('ğŸ“¦ æ”¶åˆ°éŸ³é¢‘æ•°æ®å—ï¼Œå¤§å°:', event.data.size, 'bytes, ç±»å‹:', event.data.type);
          audioChunksRef.current.push(event.data);
          
          // å½“ç´¯ç§¯è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®æ—¶æ‰å¤„ç†ï¼ˆä¼˜åŒ–å¤„ç†é€»è¾‘ï¼‰
          const totalSize = audioChunksRef.current.reduce((sum, chunk) => sum + chunk.size, 0);
          console.log('ğŸ“Š ç´¯ç§¯éŸ³é¢‘å¤§å°:', totalSize, 'bytes, å—æ•°:', audioChunksRef.current.length);
          
          // æ›´ä¸¥æ ¼çš„å¤„ç†æ¡ä»¶ï¼šç¡®ä¿éŸ³é¢‘æ•°æ®è¶³å¤Ÿå¤§ä¸”æœ‰æ•ˆ
          if (audioChunksRef.current.length >= 3 || totalSize >= 8192) { // æé«˜åˆ°8KB
            const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
            const chunksProcessed = audioChunksRef.current.length;
            audioChunksRef.current = []; // æ¸…ç©ºç¼“å­˜
            
            console.log('ğŸµ å¤„ç†éŸ³é¢‘å—ï¼Œåˆå¹¶å¤§å°:', audioBlob.size, 'bytes, æ¥æºå—æ•°:', chunksProcessed);
            
            // å¢åŠ æ›´ä¸¥æ ¼çš„éŸ³é¢‘æ•°æ®éªŒè¯
            if (sessionIdRef.current && audioBlob.size >= 4096) { // æé«˜åˆ°è‡³å°‘4KBçš„éŸ³é¢‘æ•°æ®
              try {
                // è½¬æ¢éŸ³é¢‘æ ¼å¼ä¸ºPCM
                const pcmBuffer = await convertToPCM(audioBlob);
                const uint8Array = new Uint8Array(pcmBuffer);
                const base64Audio = btoa(String.fromCharCode.apply(null, Array.from(uint8Array)));

                console.log('ğŸµ å·²å‘é€éŸ³é¢‘æ•°æ®ï¼ŒPCMå¤§å°:', pcmBuffer.byteLength, 'bytes');

                // å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
                const response = await fetch('/api/realtime-asr', {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    action: 'send_audio',
                    session_id: sessionIdRef.current,
                    audio_data: base64Audio
                  })
                });

                const result = await response.json();
                if (result.success) {
                  // å¤„ç†éƒ¨åˆ†è¯†åˆ«ç»“æœ
                  if (result.partial_text) {
                    setPartialText(result.partial_text);
                    options.onPartialResult?.(result.partial_text);
                  }
                  
                  // å¤„ç†æœ€ç»ˆè¯†åˆ«ç»“æœ
                  if (result.final_text) {
                    setFinalText(result.final_text);
                    setPartialText('');
                    options.onFinalResult?.(result.final_text);
                    console.log('ğŸ“ æœ€ç»ˆè¯†åˆ«ç»“æœ:', result.final_text);
                  }
                } else {
                  console.warn('âš ï¸ æœåŠ¡å™¨è¿”å›é”™è¯¯:', result.error);
                }
              } catch (err: any) {
                console.error('âŒ å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥:', err.message);
                // ä¸è®¾ç½®é”™è¯¯çŠ¶æ€ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€å—éŸ³é¢‘
                console.log('ğŸ”„ è·³è¿‡å½“å‰éŸ³é¢‘å—ï¼Œç»§ç»­å¤„ç†...');
              }
            } else {
              console.log('â­ï¸ éŸ³é¢‘å—å¤ªå°ï¼Œè·³è¿‡å¤„ç†:', audioBlob.size, 'bytes');
            }
          }
        }
      };

      mediaRecorder.onerror = (event) => {
        console.error('âŒ MediaRecorder é”™è¯¯:', event);
        setError('å½•éŸ³å™¨é”™è¯¯');
        options.onError?.('å½•éŸ³å™¨é”™è¯¯');
      };

      // 7. å¼€å§‹å½•éŸ³ï¼ˆæ¯3ç§’ç”Ÿæˆä¸€ä¸ªéŸ³é¢‘å—ï¼Œç¡®ä¿è¶³å¤Ÿå¤§å°ï¼‰
      mediaRecorder.start(3000);
      setIsListening(true);
      setStatus('listening');
      
      // å¼€å§‹éŸ³é¢‘ç”µå¹³ç›‘æ§
      updateAudioLevel();
      
      console.log('âœ… å¼€å§‹å½•éŸ³å’Œè¯†åˆ«');

    } catch (err: any) {
      console.error('âŒ å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', err);
      setStatus('error');
      setError(err.message);
      options.onError?.(err.message);
    }
  }, [options, updateAudioLevel]);

  // åœæ­¢å½•éŸ³
  const stopListening = useCallback(async () => {
    try {
      setStatus('stopping');
      console.log('ğŸ›‘ åœæ­¢è¯­éŸ³è¯†åˆ«...');

      // åœæ­¢å½•éŸ³
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
      }

      // åœæ­¢éŸ³é¢‘ç”µå¹³ç›‘æ§
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      // å…³é—­éŸ³é¢‘æµ
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }

      // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
      if (audioContextRef.current) {
        audioContextRef.current.close();
        audioContextRef.current = null;
      }

      // åœæ­¢æœåŠ¡å™¨ä¼šè¯
      if (sessionIdRef.current) {
        try {
          await fetch('/api/realtime-asr', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              action: 'stop',
              session_id: sessionIdRef.current
            })
          });
        } catch (err) {
          console.warn('âš ï¸ åœæ­¢ä¼šè¯è¯·æ±‚å¤±è´¥:', err);
        }
        sessionIdRef.current = null;
      }

      setIsListening(false);
      setStatus('idle');
      setAudioLevel(0);
      audioChunksRef.current = [];
      
      console.log('âœ… è¯­éŸ³è¯†åˆ«å·²åœæ­¢');

    } catch (err: any) {
      console.error('âŒ åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', err);
      setStatus('error');
      setError(err.message);
      options.onError?.(err.message);
    }
  }, [options]);

  return {
    isListening,
    status,
    partialText,
    finalText,
    audioLevel,
    error,
    startListening,
    stopListening
  };
}; 